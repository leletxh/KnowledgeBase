---
tags:
  - æ—¥è®°
---
## ollamaéƒ¨åˆ†

ollamaå®˜ç½‘æ­»æ´»è®¿é—®ä¸ä¸Šå»

åªèƒ½ç”¨MSæˆ–è€…é•œåƒ

```bash
sudo apt update && sudo apt install -y pciutils lshw zstd
pip install modelscope -U
modelscope download --model=modelscope/ollama-linux --local_dir ./ollama-linux --revision v0.14.1
cd ollama-linux
chmod +x ollama-modelscope-install.sh
./ollama-modelscope-install.sh
```

## æ¨¡å‹ä¸‹è½½éƒ¨åˆ†

ç”¨çš„è¿˜æ˜¯MSï¼Œä¸»è¦æ˜¯é‡åŒ–äº†ï¼Œéƒ½96GBæ˜¾å­˜äº†è¿˜è·‘ä¸äº†å…¨é‡

```bash
modelscope download --model Qwen/Qwen3-Next-80B-A3B-Instruct-GGUF Qwen3-Next-80B-A3B-Instruct-Q8_0.gguf --local_dir /root/autodl-tmp/model/
```
## å¯åŠ¨éƒ¨åˆ†

æ‡’å¾—çœ‹docäº†ï¼Œè®©qwenå†™äº†ä¸€æ®µ

```bash
#!/bin/bash

# ==============================
# Qwen3-80B-Q8_0 ä¸€é”®å¯åŠ¨è„šæœ¬
# é€‚é… AutoDL å®¹å™¨ + RTX PRO 6000 96GB
# é¿å…ç³»ç»Ÿç›˜å†™æ»¡ï¼Œæ¨¡å‹å­˜äºæ•°æ®ç›˜
# ==============================

set -e  # é‡é”™é€€å‡º

# --- é…ç½®åŒº ---
MODEL_NAME="qwen3-80b-next"
GGUF_PATH="/root/autodl-tmp/model/Qwen3-Next-80B-A3B-Instruct-Q8_0.gguf"
DATA_DIR="/root/autodl-tmp"
OLLAMA_MODELS_DIR="${DATA_DIR}/ollama-models"
MODFILE_DIR="${DATA_DIR}/model"

# --- ç¯å¢ƒå˜é‡ ---
export OLLAMA_MODELS="${OLLAMA_MODELS_DIR}"
export PATH="$PATH:/usr/local/bin"

# --- å‡½æ•°ï¼šå¯åŠ¨ ollama æœåŠ¡ ---
start_ollama() {
    echo "[*] æ£€æŸ¥ Ollama æœåŠ¡..."
    if pgrep -x "ollama" > /dev/null; then
        echo "[+] Ollama å·²åœ¨è¿è¡Œ"
    else
        echo "[*] å¯åŠ¨ Ollama æœåŠ¡..."
        mkdir -p "${OLLAMA_MODELS_DIR}"
        nohup ollama serve > /root/ollama.log 2>&1 &
        sleep 5
        if ! pgrep -x "ollama" > /dev/null; then
            echo "[-] Ollama å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—: tail -f /root/ollama.log"
            exit 1
        fi
        echo "[+] Ollama æœåŠ¡å·²å¯åŠ¨"
    fi
}

# --- å‡½æ•°ï¼šåˆ›å»º Modelfile ---
create_modelfile() {
    echo "[*] åˆ›å»º Modelfile..."
    cat > "${MODFILE_DIR}/Modelfile" <<EOF
FROM ${GGUF_PATH}

TEMPLATE "{{ if .System }}<|im_start|>system
{{ .System }}<|im_end|>
{{ end }}{{ if .Prompt }}<|im_start|>user
{{ .Prompt }}<|im_end|>
<|im_start|>assistant
{{ end }}"

PARAMETER num_ctx 4096
PARAMETER stop "<|im_end|>"
EOF
    echo "[+] Modelfile å·²ç”Ÿæˆ"
}

# --- å‡½æ•°ï¼šåˆ›å»ºæ¨¡å‹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰---
create_model_if_needed() {
    echo "[*] æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨..."
    if ollama list | grep -q "^${MODEL_NAME}"; then
        echo "[+] æ¨¡å‹ ${MODEL_NAME} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º"
    else
        echo "[*] åˆ›å»ºæ¨¡å‹ ${MODEL_NAME} ..."
        create_modelfile
        ollama create "${MODEL_NAME}" -f "${MODFILE_DIR}/Modelfile"
        echo "[+] æ¨¡å‹åˆ›å»ºæˆåŠŸï¼"
    fi
}

# --- ä¸»æµç¨‹ ---
echo "ğŸš€ å¯åŠ¨ Qwen3-80B-Q8_0 (PRO 6000 96GB) ..."

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if [ ! -f "${GGUF_PATH}" ]; then
    echo "[-] é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: ${GGUF_PATH}"
    exit 1
fi

# åˆ›å»ºç›®å½•
mkdir -p "${OLLAMA_MODELS_DIR}"

# å¯åŠ¨æœåŠ¡
start_ollama

# åˆ›å»ºæ¨¡å‹
create_model_if_needed

# è¿è¡Œæ¨¡å‹
echo "ğŸ’¬ è¿›å…¥å¯¹è¯æ¨¡å¼ï¼ˆè¾“å…¥ 'exit' æˆ– Ctrl+D é€€å‡ºï¼‰..."
echo "--------------------------------------------------"
ollama run "${MODEL_NAME}"
```